{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6753c54-9812-48ae-aed4-9b3c8585b7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b88c4-45b6-4295-b54a-296598203652",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rng_itrs in [0]: # Put deired list of RNG values\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    torch.cuda.empty_cache()\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    import snntorch as snn\n",
    "    from snntorch import surrogate\n",
    "\n",
    "    from timeit import default_timer\n",
    "    from pytorch_wavelets import DWT, IDWT # (or import DWT, IDWT)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(rng_itrs)\n",
    "    np.random.seed(rng_itrs)\n",
    "\n",
    "\n",
    "    from utilities_0 import *\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     from utilities_1 import *\n",
    "#     device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # %%\n",
    "    \"\"\" Def: 2d Wavelet layer \"\"\"\n",
    "    class WaveConv2d(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, level, dummy):\n",
    "            super(WaveConv2d, self).__init__()\n",
    "\n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = out_channels\n",
    "            self.level = level\n",
    "            self.dwt_ = DWT(J=self.level, mode='symmetric', wave='db6').to(dummy.device)\n",
    "            self.mode_data, _ = self.dwt_(dummy)\n",
    "            self.modes1 = self.mode_data.shape[-2]\n",
    "            self.modes2 = self.mode_data.shape[-1]\n",
    "\n",
    "            self.scale = (1 / (in_channels * out_channels))\n",
    "            self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "            self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2))\n",
    "            \n",
    "        # Convolution\n",
    "        def mul2d(self, input, weights):\n",
    "            # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "            return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "        def forward(self, x):\n",
    "            batchsize = x.shape[0]\n",
    "            # Compute single tree Discrete Wavelet coefficients using some wavelet\n",
    "            dwt = DWT(J=self.level, mode='symmetric', wave='db6').to(x.device)\n",
    "            x_ft, x_coeff = dwt(x)\n",
    "\n",
    "            # Multiply relevant Wavelet modes\n",
    "            out_ft = torch.zeros(batchsize, self.out_channels,  x_ft.shape[-2], x_ft.shape[-1], device=x.device)\n",
    "            out_ft = self.mul2d(x_ft, self.weights1)\n",
    "            # Multiply the finer wavelet coefficients\n",
    "            x_coeff[-1][:,:,0,:,:] = self.mul2d(x_coeff[-1][:,:,0,:,:].clone(), self.weights2)\n",
    "            \n",
    "            # Return to physical space        \n",
    "            idwt = IDWT(mode='symmetric', wave='db6').to(x.device)\n",
    "            x = idwt((out_ft, x_coeff))\n",
    "            return x\n",
    "\n",
    "    \"\"\" The forward operation \"\"\"\n",
    "    class WNO2d(nn.Module):\n",
    "        def __init__(self, width, level, dummy_data):\n",
    "            super(WNO2d, self).__init__()\n",
    "\n",
    "            self.level = level\n",
    "            self.dummy_data = dummy_data\n",
    "            self.width = width\n",
    "            self.padding = 1 # pad the domain when required\n",
    "            self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "            self.conv0 = WaveConv2d(self.width, self.width, self.level, self.dummy_data)\n",
    "            self.conv1 = WaveConv2d(self.width, self.width, self.level, self.dummy_data)\n",
    "            self.conv2 = WaveConv2d(self.width, self.width, self.level, self.dummy_data)\n",
    "            self.conv3 = WaveConv2d(self.width, self.width, self.level, self.dummy_data)\n",
    "            self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "            self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "            self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "            self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "            self.fc1 = nn.Linear(self.width, 128)\n",
    "            self.fc2 = nn.Linear(128, 1)\n",
    "            \n",
    "            beta = torch.rand(52,52)\n",
    "            thr = torch.rand(52,52)   \n",
    "            self.lif1 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "            \n",
    "            beta = torch.rand(52,52)\n",
    "            thr = torch.rand(52,52)   \n",
    "            self.lif2 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "            \n",
    "            beta = torch.rand(52,52)\n",
    "            thr = torch.rand(52,52)    \n",
    "            self.lif3 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())        \n",
    "            \n",
    "            beta = torch.rand(128)\n",
    "            thr = torch.rand(128)   \n",
    "            self.lif4 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "        def forward(self, x):\n",
    "            n_spikes = 1\n",
    "            x_spiketime = torch.empty([x.shape[0], 51, 51, 128, n_spikes]).to(x.device)\n",
    "\n",
    "            mem1 = self.lif1.init_leaky()\n",
    "            mem2 = self.lif2.init_leaky()\n",
    "            mem3 = self.lif3.init_leaky()\n",
    "            mem4 = self.lif4.init_leaky()\n",
    "\n",
    "            grid = self.get_grid(x.shape, x.device)\n",
    "            x = torch.cat((x, grid), dim=-1)\n",
    "            inputs = x\n",
    "\n",
    "            s1 = 0\n",
    "            s2 = 0\n",
    "            s3 = 0\n",
    "            s4 = 0        \n",
    "            for i in range(0,n_spikes):\n",
    "\n",
    "                x = self.fc0(inputs)\n",
    "                x = x.permute(0, 3, 1, 2)\n",
    "                x = F.pad(x, [0,self.padding, 0,self.padding]) # padding, if required\n",
    "\n",
    "                x1 = self.conv0(x)\n",
    "                x2 = self.w0(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem1 = self.lif1(x, mem1)\n",
    "                x = (x*spike)\n",
    "\n",
    "                s1 += spike.sum()/(x.shape[0]*64*52*52)\n",
    "\n",
    "                x1 = self.conv1(x)\n",
    "                x2 = self.w1(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem2 = self.lif2(x, mem2)\n",
    "                x = (x*spike)\n",
    "\n",
    "                s2 += spike.sum()/(x.shape[0]*64*52*52)\n",
    "\n",
    "                x1 = self.conv2(x)\n",
    "                x2 = self.w2(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem3 = self.lif3(x, mem3)\n",
    "                x = (x*spike)\n",
    "\n",
    "                s3 += spike.sum()/(x.shape[0]*64*52*52)\n",
    "\n",
    "                x1 = self.conv3(x)\n",
    "                x2 = self.w3(x)\n",
    "                x = x1 + x2\n",
    "\n",
    "                x = x[..., :-self.padding, :-self.padding] # removing padding, when applicable\n",
    "                x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "                x = self.fc1(x)\n",
    "                spike,mem4 = self.lif4(x, mem4)\n",
    "                x = (x*spike)\n",
    "\n",
    "                s4 += spike.sum()/(x.shape[0]*51*51*128)\n",
    "\n",
    "                x_spiketime[:,:,:,:,i] = x\n",
    "\n",
    "            x = torch.mean(x_spiketime, 4)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "            return s1/n_spikes, s2/n_spikes, s3/n_spikes, s4/n_spikes, x\n",
    "\n",
    "        def get_grid(self, shape, device):\n",
    "            # The grid of the solution\n",
    "            batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "            gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "            gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "            gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "            gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "            return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Model configurations \"\"\"\n",
    "\n",
    "    PATH = '/DATA/SG/WNO/data/Darcy_Triangular_FNO.mat'\n",
    "    ntrain = 1900\n",
    "    ntest = 100\n",
    "\n",
    "    batch_size = 25\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 500\n",
    "    step_size = 50\n",
    "    gamma = 0.75\n",
    "\n",
    "    level = 3\n",
    "    width = 64\n",
    "\n",
    "    r = 2\n",
    "    h = int(((101 - 1)/r) + 1)\n",
    "    s = h\n",
    "\n",
    "    # %%\n",
    "    \"\"\" Read data \"\"\"\n",
    "    reader = MatReader(PATH)\n",
    "    x_train = reader.read_field('boundCoeff')[:ntrain,::r,::r][:,:s,:s]\n",
    "    y_train = reader.read_field('sol')[:ntrain,::r,::r][:,:s,:s]\n",
    "\n",
    "    x_test = reader.read_field('boundCoeff')[-ntest:,::r,::r][:,:s,:s]\n",
    "    y_test = reader.read_field('sol')[-ntest:,::r,::r][:,:s,:s]\n",
    "\n",
    "    x_normalizer = UnitGaussianNormalizer(x_train)\n",
    "    x_train = x_normalizer.encode(x_train)\n",
    "    x_test = x_normalizer.encode(x_test)\n",
    "\n",
    "    y_normalizer = UnitGaussianNormalizer(y_train)\n",
    "    y_train = y_normalizer.encode(y_train)\n",
    "\n",
    "    x_train = x_train.reshape(ntrain,s,s,1)\n",
    "    x_test = x_test.reshape(ntest,s,s,1)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # %%\n",
    "    \"\"\" The model definition \"\"\"\n",
    "    model = WNO2d(width, level, x_train.permute(0,3,1,2)).to(device)\n",
    "    print(count_params(model))\n",
    "\n",
    "    from torchinfo import summary\n",
    "    print(summary(model, input_size=(batch_size, s, s, 1)))\n",
    "\n",
    "    # %%\n",
    "\n",
    "    model = WNO2d(width, level, x_train.permute(0,3,1,2)).to(device)\n",
    "\n",
    "    \"\"\" Training and testing \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    train_loss = torch.zeros(epochs)\n",
    "    test_loss = torch.zeros(epochs)\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    y_normalizer.cuda()\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_l2 = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            s1,s2,s3,s4,out = model(x)\n",
    "            out = out.reshape(batch_size, s, s)\n",
    "            out = y_normalizer.decode(out)\n",
    "            y = y_normalizer.decode(y)\n",
    "\n",
    "            loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "            \n",
    "            nl = loss + (s1+s2+s3+s4) # weights for different losses can be changed here\n",
    "            nl.backward()\n",
    "            optimizer.step()\n",
    "            train_l2 += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        test_l2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                s1,s2,s3,s4,out = model(x)\n",
    "                out = out.reshape(batch_size, s, s)\n",
    "                out = y_normalizer.decode(out)\n",
    "\n",
    "                test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "\n",
    "        train_l2/= ntrain\n",
    "        test_l2 /= ntest\n",
    "\n",
    "        train_loss[ep] = train_l2\n",
    "        test_loss[ep] = test_l2\n",
    "\n",
    "        t2 = default_timer()\n",
    "        print('%5d %15.4f %15.4e %15.4e %7.4f %7.4f %7.4f %7.4f'%(ep, t2-t1, train_l2, test_l2, s1, s2, s3, s4))\n",
    "\n",
    "#     # %%\n",
    "\n",
    "    filename = './model/RNG_'+str(rng_itrs)+'_Model_2DDarcyTriangular_1900TDS_WNO_VSNN_New_LOSS_1_1_LearnBeTh.pt'\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    # %%\n",
    "\n",
    "    s = h\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "\n",
    "    pred = torch.zeros([y_test.shape[0], y_test.shape[1], y_test.shape[2]])\n",
    "    myloss = LpLoss(size_average=False)\n",
    "\n",
    "    filename = './model/RNG_'+str(rng_itrs)+'_Model_2DDarcyTriangular_1900TDS_WNO_VSNN_New_LOSS_1_1_LearnBeTh.pt'\n",
    "\n",
    "    loaded_model = WNO2d(width, level, x_train.permute(0,3,1,2)).to(device)\n",
    "    loaded_model.load_state_dict(torch.load(filename))\n",
    "\n",
    "    index = 0\n",
    "    test_e = torch.zeros(y_test.shape[0])\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n",
    "    \n",
    "    ts1 = 0\n",
    "    ts2 = 0\n",
    "    ts3 = 0\n",
    "    ts4 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            test_l2 = 0\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            s1,s2,s3,s4,out = loaded_model(x)\n",
    "            out = out.reshape(1, s, s)\n",
    "            out = y_normalizer.decode(out)\n",
    "            pred[index,:,:] = out\n",
    "\n",
    "            test_l2 = myloss(out.reshape(1, s, s), y.reshape(1, s, s)).item()\n",
    "            test_e[index] = test_l2\n",
    "\n",
    "            # print(index, test_l2)\n",
    "            index = index + 1\n",
    "            ts1 += s1\n",
    "            ts2 += s2\n",
    "            ts3 += s3\n",
    "            ts4 += s4\n",
    "\n",
    "    print('Mean Testing Error:', 100*torch.mean(test_e).numpy(), '%')\n",
    "    print('%.4f %.4f %.4f %.4f'%(100*ts1.item()/ntest, 100*ts2.item()/ntest, 100*ts3.item()/ntest, 100*ts4.item()/ntest))\n",
    "    \n",
    "    # %%\n",
    "\n",
    "    m = pred.numpy()\n",
    "\n",
    "    plt.figure(constrained_layout=False, figsize = (7, 14))\n",
    "    plt.subplots_adjust(hspace=0.75)\n",
    "    index = 0\n",
    "\n",
    "    for value in range(y_test.shape[0]):\n",
    "        if value % 60 == 1:\n",
    "            plt.subplot(5,2, index+1)\n",
    "            plt.imshow(y_test[value,:,:], origin='lower', cmap='seismic',\n",
    "                       vmin = np.min(y_test[value,:,:].numpy()), vmax = np.max(y_test[value,:,:].numpy()))\n",
    "            plt.colorbar()\n",
    "            plt.title('Actual')\n",
    "\n",
    "            plt.subplot(5,2, index+1+2)\n",
    "            plt.imshow(m[value,:,:], origin='lower', cmap='seismic',\n",
    "                       vmin = np.min(y_test[value,:,:].numpy()), vmax = np.max(y_test[value,:,:].numpy()))\n",
    "            plt.colorbar()\n",
    "            plt.title('Mean')\n",
    "\n",
    "            index = index + 1\n",
    "    \n",
    "    plt.show()\n",
    "    print((100*myloss(y_test, torch.tensor(m)).item())/40)\n",
    "    print(100*torch.sum((y_test-torch.tensor(m))**2).item())\n",
    "\n",
    "    # %%\n",
    "\n",
    "    for marker in ([1-1,5-1,15-1,29-1]):\n",
    "        plt.figure(constrained_layout=False, figsize = (10, 3))\n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        index = 0\n",
    "        for value in range(y_test.shape[0]):\n",
    "            if value % 60 == 1:\n",
    "                plt.subplot(1,2, index+1)\n",
    "                plt.plot(y_test[value,marker,:],'r')\n",
    "                plt.plot(m[value,marker,:],'b')\n",
    "                index = index + 1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3206a3-c165-454b-b2bf-c8ce45cfadb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455b173-0c1d-4d87-96cd-93d6b12b368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be0633-259d-402b-969f-f76d69c3a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\" Plotting \"\"\"\n",
    "\n",
    "    plt.figure(figsize = (14, 2))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    index = 0\n",
    "    for value in  [0,10]:\n",
    "        plt.subplot(1,4, index*2+1)\n",
    "        plt.imshow(y_test[value,:,:], label='True', cmap='seismic', origin='lower')\n",
    "        # plt.title('Actual')\n",
    "        plt.xticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        plt.yticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "        xcord=np.array([26,26,24,24]); ycord=np.array([0,21,21,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord, color = 'white')\n",
    "        \n",
    "        xcord=np.array([0,0,25,0]); ycord=np.array([0,50,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        xcord=np.array([50,50,25,50]); ycord=np.array([0,50,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        \n",
    "        xcord=np.array([0,0,50,50,0]); ycord=np.array([50,44,44,50,50])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        \n",
    "\n",
    "        index += 1\n",
    "        \n",
    "    plt.savefig('/DATA/SG/NINN_WNO/Final_codes/Plots/DTri_GT.pdf')\n",
    "    plt.savefig('/DATA/SG/NINN_WNO/Final_codes/Plots/DTri_GT.png')    \n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\" Plotting \"\"\"\n",
    "\n",
    "    plt.figure(figsize = (14, 2))\n",
    "    # plt.subplots_adjust(hspace=0.7)\n",
    "    index = 0\n",
    "    for value in [0,10]:\n",
    "        plt.subplot(1,4, index*2+1)\n",
    "        plt.imshow(m[value,:,:], cmap='seismic', origin='lower')\n",
    "        # plt.title('Identified')\n",
    "        plt.xticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        plt.yticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "        xcord=np.array([26,26,24,24]); ycord=np.array([0,21,21,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord, color = 'white')\n",
    "        \n",
    "        xcord=np.array([0,0,25,0]); ycord=np.array([0,51,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        xcord=np.array([51,51,25,51]); ycord=np.array([0,51,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        \n",
    "        xcord=np.array([0,0,51,51,0]); ycord=np.array([51,44,44,51,51])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "                \n",
    "\n",
    "        plt.subplot(1,4, index*2+2)\n",
    "        plt.imshow(np.abs(y_test[value,:,:]-m[value,:,:]), cmap='seismic', origin='lower')\n",
    "        # plt.title('Error')\n",
    "        plt.xticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        plt.yticks([0,25,50],[0,0.5,1], fontsize = 14)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.formatter.set_powerlimits((0, 0))\n",
    "        cbar.update_ticks()\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "        cbar.ax.yaxis.get_offset_text().set(size=14)\n",
    "        plt.margins(0)\n",
    "        \n",
    "        xcord=np.array([26,26,24,24]); ycord=np.array([0,21,21,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord, color = 'white')\n",
    "        \n",
    "        xcord=np.array([0,0,25,0]); ycord=np.array([0,50,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        xcord=np.array([50,50,25,50]); ycord=np.array([0,50,44,0])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        \n",
    "        xcord=np.array([0,0,50,50,0]); ycord=np.array([50,44,44,50,50])\n",
    "        plt.axis('square'); plt.fill_between(xcord,ycord,color='white')\n",
    "        \n",
    "        index = index + 1\n",
    "    \n",
    "    plt.savefig('/DATA/SG/NINN_WNO/Final_codes/Plots/DTri_VSNN_LearnBeTh_NL_1_1.pdf')\n",
    "    plt.savefig('/DATA/SG/NINN_WNO/Final_codes/Plots/DTri_VSNN_LearnBeTh_NL_1_1.png')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280759d-9f38-4bc6-a0ef-afe8d353f4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
