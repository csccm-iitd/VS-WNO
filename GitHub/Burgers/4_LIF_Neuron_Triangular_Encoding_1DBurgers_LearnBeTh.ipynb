{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77629f5-6e5e-49ec-b735-43d591ce4591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dcc0b-beea-4556-8a6e-24c3f3e14a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "for rng_itrs in [0]: # Put deired list of RNG values\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    torch.cuda.empty_cache()\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import snntorch as snn\n",
    "    from snntorch import surrogate\n",
    "    from snntorch import functional as SF\n",
    "    from snntorch import utils\n",
    "    from snntorch import spikegen\n",
    "\n",
    "    from timeit import default_timer\n",
    "    from pytorch_wavelets import DWT1D, IDWT1D\n",
    "\n",
    "    torch.manual_seed(rng_itrs)\n",
    "    np.random.seed(rng_itrs)\n",
    "\n",
    "    from utilities_0 import *\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # from utilities_1 import *\n",
    "    # device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # %%\n",
    "    \n",
    "    def encode(x, nsteps):\n",
    "\n",
    "        dx = 1/nsteps\n",
    "\n",
    "        x = x//dx\n",
    "\n",
    "        x_encoded = torch.zeros(x.shape[0],x.shape[1],nsteps)\n",
    "\n",
    "        for i in range(0,x.shape[0]):\n",
    "            for j in range(0,x.shape[1]):\n",
    "                x_encoded[i,j,0:int(x[i,j])] = 1\n",
    "\n",
    "        return x_encoded\n",
    "\n",
    "    \"\"\" Def: 1d Wavelet layer \"\"\"\n",
    "\n",
    "    class WaveConv1d(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, level, dummy):\n",
    "            super(WaveConv1d, self).__init__()\n",
    "            \n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = out_channels\n",
    "\n",
    "            self.level = level\n",
    "            self.wavelet = 'db6'\n",
    "            self.mode = 'symmetric'\n",
    "\n",
    "            self.dwt_ = DWT1D(J=self.level, mode=self.mode, wave=self.wavelet).to(dummy.device)\n",
    "            self.x_dwt, _ = self.dwt_(dummy) \n",
    "            self.modes = self.x_dwt.shape[-1]\n",
    "\n",
    "            self.scale = (1 / (in_channels*out_channels))\n",
    "            self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes))\n",
    "            self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes))\n",
    "\n",
    "        def mul2d(self, input, weights):\n",
    "            # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "            return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "        def forward(self, x):\n",
    "            batchsize = x.shape[0]\n",
    "            # Compute single tree Discrete Wavelet coefficients using some wavelet     \n",
    "            dwt = DWT1D(J=self.level, mode=self.mode, wave=self.wavelet).to(x.device)\n",
    "            x_ft, x_coeff = dwt(x)\n",
    "\n",
    "            # Multiply the final low pass and high pass coefficients\n",
    "            out_ft = torch.zeros(batchsize, self.out_channels, x_ft.shape[-1],  device=x.device)\n",
    "            out_ft = self.mul2d(x_ft, self.weights1)\n",
    "            x_coeff[-1] = self.mul2d(x_coeff[-1], self.weights2)\n",
    "\n",
    "            # Reconstruct the signal\n",
    "            idwt = IDWT1D(mode=self.mode, wave=self.wavelet).to(x.device)\n",
    "            x = idwt((out_ft, x_coeff))        \n",
    "            return x\n",
    "\n",
    "    \"\"\" The forward operation \"\"\"\n",
    "\n",
    "    class WNO1d(nn.Module):\n",
    "        def __init__(self, level, width, dummy_data):\n",
    "            super(WNO1d, self).__init__()\n",
    "\n",
    "            self.level1 = level\n",
    "            self.width = width\n",
    "            self.padding = 2 # pad the domain if input is non-periodic\n",
    "            self.dummy_data = dummy_data\n",
    "\n",
    "            self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n",
    "\n",
    "            self.conv0 = WaveConv1d(self.width, self.width, self.level1, self.dummy_data)\n",
    "            self.conv1 = WaveConv1d(self.width, self.width, self.level1, self.dummy_data)\n",
    "            self.conv2 = WaveConv1d(self.width, self.width, self.level1, self.dummy_data)\n",
    "            self.conv3 = WaveConv1d(self.width, self.width, self.level1, self.dummy_data)\n",
    "            self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "            self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "            self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "            self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "            self.fc1 = nn.Linear(self.width, 128)\n",
    "            self.fc2 = nn.Linear(128, 1)\n",
    "            \n",
    "            beta = torch.rand(1024)\n",
    "            thr = torch.rand(1024)   \n",
    "            self.lif1 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "            \n",
    "            beta = torch.rand(1024)\n",
    "            thr = torch.rand(1024)   \n",
    "            self.lif2 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "            \n",
    "            beta = torch.rand(1024)\n",
    "            thr = torch.rand(1024)   \n",
    "            self.lif3 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())        \n",
    "            \n",
    "            beta = torch.rand(128)\n",
    "            thr = torch.rand(128)   \n",
    "            self.lif4 = snn.Leaky(beta=beta, threshold=thr, reset_mechanism='zero',\n",
    "                                  learn_beta=True, learn_threshold=True,\n",
    "                                  spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "        def forward(self, x):\n",
    "            n_spikes = 10\n",
    "            x_spiketime = torch.empty([x.shape[0], x.shape[2], 128, n_spikes]).to(x.device)\n",
    "\n",
    "            inputs = x\n",
    "\n",
    "            mem1 = self.lif1.init_leaky()\n",
    "            mem2 = self.lif2.init_leaky()\n",
    "            mem3 = self.lif3.init_leaky()\n",
    "            mem4 = self.lif4.init_leaky()\n",
    "\n",
    "            s1 = 0\n",
    "            s2 = 0\n",
    "            s3 = 0\n",
    "            s4 = 0        \n",
    "\n",
    "            for i in range(0,n_spikes):\n",
    "                x = inputs[:,i,:,:]\n",
    "                \n",
    "                grid = self.get_grid(x.shape, x.device)\n",
    "                x = torch.cat((x, grid), dim=-1)\n",
    "\n",
    "                x = self.fc0(x)\n",
    "                \n",
    "                x = x.permute(0, 2, 1)\n",
    "\n",
    "                x1 = self.conv0(x)\n",
    "                x2 = self.w0(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem1 = self.lif1(x, mem1)\n",
    "                x = spike\n",
    "\n",
    "                s1 += spike.sum()/(x.shape[0]*64*1024)\n",
    "\n",
    "                x1 = self.conv1(x)\n",
    "                x2 = self.w1(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem2 = self.lif2(x, mem2)\n",
    "                x = spike\n",
    "\n",
    "                s2 += spike.sum()/(x.shape[0]*64*1024)\n",
    "\n",
    "                x1 = self.conv2(x)\n",
    "                x2 = self.w2(x)\n",
    "                x = x1 + x2\n",
    "                spike,mem3 = self.lif3(x, mem3)\n",
    "                x = spike\n",
    "\n",
    "                s3 += spike.sum()/(x.shape[0]*64*1024)\n",
    "\n",
    "                x1 = self.conv3(x)\n",
    "                x2 = self.w3(x)\n",
    "                x = x1 + x2\n",
    "\n",
    "                x = x.permute(0, 2, 1)\n",
    "\n",
    "                x = self.fc1(x)\n",
    "                spike,mem4 = self.lif4(x, mem4)\n",
    "                x = spike\n",
    "\n",
    "                s4 += spike.sum()/(x.shape[0]*1024*128)\n",
    "\n",
    "                x_spiketime[:,:,:,i] = x\n",
    "\n",
    "            x = torch.mean(x_spiketime, 3)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "            return s1/n_spikes, s2/n_spikes, s3/n_spikes, s4/n_spikes, x\n",
    "\n",
    "        def get_grid(self, shape, device):\n",
    "            # The grid of the solution\n",
    "            batchsize, size_x = shape[0], shape[1]\n",
    "            gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "            gridx = gridx.reshape(1, size_x, 1).repeat([batchsize, 1, 1])\n",
    "            return gridx.to(device)\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Model configurations \"\"\"\n",
    "\n",
    "    ntrain = 1000\n",
    "    ntest = 100\n",
    "\n",
    "    sub = 2**3\n",
    "    h = 2**13 // sub\n",
    "    s = h\n",
    "\n",
    "    batch_size = 10\n",
    "    learning_rate = 5e-5\n",
    "\n",
    "    epochs = 500\n",
    "    step_size = 100\n",
    "    gamma = 0.5\n",
    "\n",
    "    level = 8\n",
    "    width = 64\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Read data \"\"\"\n",
    "\n",
    "    import scipy.io as sio\n",
    "\n",
    "    dataloader = sio.loadmat('/DATA/SG/WNO/data/burgers_data_R10.mat')\n",
    "\n",
    "    x_data = torch.tensor(dataloader['a'][:,::sub], dtype=torch.float)\n",
    "    y_data = torch.tensor(dataloader['u'][:,::sub], dtype=torch.float)\n",
    "\n",
    "    x_train = x_data[:ntrain,:]\n",
    "    y_train = y_data[:ntrain,:]\n",
    "    x_test = x_data[-ntest:,:]\n",
    "    y_test = y_data[-ntest:,:]\n",
    "\n",
    "    max_x = torch.max(x_train)\n",
    "    min_x = torch.min(x_train)\n",
    "\n",
    "    x_train = (x_train-min_x)/(max_x-min_x)\n",
    "    x_test = (x_test-min_x)/(max_x-min_x)\n",
    "\n",
    "    n_spikes = 10\n",
    "\n",
    "    x_train_re = torch.zeros([ntrain, n_spikes, 1024, 1], dtype = torch.float)\n",
    "    x_test_re = torch.zeros([ntest, n_spikes, 1024, 1], dtype = torch.float)\n",
    "\n",
    "    for i in range(0,ntrain):\n",
    "        x_train_re[i] = encode(x_train[i].detach().clone()[:, None], n_spikes).permute(2,0,1)\n",
    "\n",
    "    for i in range(0,ntest):\n",
    "        x_test_re[i] = encode(x_test[i].detach().clone()[:, None], n_spikes).permute(2,0,1)\n",
    "\n",
    "    x_train = x_train.reshape(ntrain,s,1)\n",
    "    x_test = x_test.reshape(ntest,s,1)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_re, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_re, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" The model definition \"\"\"\n",
    "    model = WNO1d(level, width, x_train[0:1].permute(0, 2, 1)).to(device)\n",
    "    print(count_params(model))\n",
    "\n",
    "    from torchinfo import summary\n",
    "    print(summary(model, input_size=(batch_size, 10, 1024, 1)))\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Training and testing \"\"\"\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    model = WNO1d(level, width, x_train[0:1].permute(0, 2, 1)).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_mse = 0\n",
    "        train_l2 = 0\n",
    "\n",
    "        itr_tr = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            s1,s2,s3,s4,out = model(x)\n",
    "\n",
    "            itr_tr += 1\n",
    "\n",
    "            mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "            l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "\n",
    "            new_loss = l2\n",
    "\n",
    "            new_loss.backward() # new loss\n",
    "\n",
    "            optimizer.step()\n",
    "            train_mse += mse.item()\n",
    "            train_l2 += l2.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        test_l2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                s1,s2,s3,s4,out = model(x)\n",
    "                test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "        train_mse /= len(train_loader)\n",
    "        train_l2 /= ntrain\n",
    "        test_l2 /= ntest\n",
    "\n",
    "        t2 = default_timer()\n",
    "\n",
    "        if ep%1 == 0:\n",
    "            print('%5d %10.4f %15.4e %15.4e %15.4e %10.4f %10.4f %10.4f %10.4f'%(ep, t2-t1, train_mse,\n",
    "                                                                                 train_l2, test_l2, s1,\n",
    "                                                                                 s2, s3, s4))\n",
    "\n",
    "    # %%\n",
    "\n",
    "    filename = './model/RNG_'+str(rng_itrs)+'_Model_1DBurgers_1000TDS_WNO_SNN_TE_LearnBeTh_LR0p0001.pt'\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    pred = torch.zeros([y_test.shape[0], y_test.shape[1]])\n",
    "    myloss = LpLoss(size_average=False)\n",
    "\n",
    "    filename = './model/RNG_'+str(rng_itrs)+'_Model_1DBurgers_1000TDS_WNO_SNN_TE_LearnBeTh_LR0p0001.pt'\n",
    "\n",
    "    loaded_model = WNO1d(level, width, x_train[0:1].permute(0, 2, 1)).to(device)\n",
    "    loaded_model.load_state_dict(torch.load(filename))\n",
    "\n",
    "    index = 0\n",
    "    test_e = torch.zeros(y_test.shape[0])\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_re, y_test), batch_size=1, shuffle=False)\n",
    "\n",
    "    ts1 = 0\n",
    "    ts2 = 0\n",
    "    ts3 = 0\n",
    "    ts4 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            test_l2 = 0\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            s1,s2,s3,s4,out = loaded_model(x)\n",
    "            pred[index,:] = out.view(-1)\n",
    "\n",
    "            test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "            test_e[index] = test_l2\n",
    "\n",
    "            index = index + 1\n",
    "            ts1 += s1\n",
    "            ts2 += s2\n",
    "            ts3 += s3\n",
    "            ts4 += s4\n",
    "\n",
    "    print('%.4f'%(100*torch.mean(test_e)))\n",
    "    print('%.4f %.4f %.4f %.4f'%(100*ts1.item()/ntest, 100*ts2.item()/ntest, 100*ts3.item()/ntest, 100*ts4.item()/ntest))\n",
    "\n",
    "    # %%\n",
    "\n",
    "    \"\"\" Plotting \"\"\"\n",
    "\n",
    "    m = pred.numpy()\n",
    "\n",
    "    for i in range(0,y_test.shape[0],10):\n",
    "        plt.plot(y_test[i, :].numpy(), 'r', label='Actual')\n",
    "        plt.plot(m[i,:], 'k', label='Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330c441-8671-40f3-aa9a-e7ac360491e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
